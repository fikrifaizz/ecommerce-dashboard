{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fikrifaizz/ecommerce-dashboard/blob/main/notebooks/data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t3JgRGFzKKYh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup Selesai. Siap melakukan cleaning.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Setup Path\n",
        "raw_path = '../data/raw/'\n",
        "processed_path = '../data/processed/'\n",
        "\n",
        "# Buat folder processed jika belum ada\n",
        "os.makedirs(processed_path, exist_ok=True)\n",
        "\n",
        "print(\"Setup Selesai. Siap melakukan cleaning.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import csv # Pastikan import ini ada\n",
        "\n",
        "def clean_and_save(filename):\n",
        "    print(f\"\\n--- Memproses: {filename} ---\")\n",
        "    \n",
        "    # 1. Load Data\n",
        "    try:\n",
        "        df = pd.read_csv(os.path.join(raw_path, filename))\n",
        "    except Exception as e:\n",
        "        print(f\"Error saat membaca file: {e}\")\n",
        "        return\n",
        "\n",
        "    # 2. PROSES PEMBERSIHAN KHUSUS\n",
        "    \n",
        "    # A. Kasus REVIEWS: Hapus Enter (\\n)\n",
        "    if 'olist_order_reviews' in filename:\n",
        "        print(\"   Fixing: Menghapus karakter newline di komentar...\")\n",
        "        cols = ['review_comment_title', 'review_comment_message']\n",
        "        for col in cols:\n",
        "            # Ganti enter dengan spasi\n",
        "            df[col] = df[col].astype(str).str.replace(r'[\\n\\r]', ' ', regex=True)\n",
        "            # Ganti string 'nan' menjadi kosong agar jadi NULL yang bersih\n",
        "            df[col] = df[col].replace('nan', '')\n",
        "\n",
        "    # B. Kasus GEOLOCATION: Hapus Duplikat Massive\n",
        "    if 'olist_geolocation' in filename:\n",
        "        initial_rows = len(df)\n",
        "        df = df.drop_duplicates()\n",
        "        dropped = initial_rows - len(df)\n",
        "        print(f\"   Optimization: Menghapus {dropped:,} baris duplikat.\")\n",
        "\n",
        "    # C. Kasus PRODUCTS: Isi Kategori Null\n",
        "    if 'olist_products' in filename:\n",
        "        print(\"   Fixing: Mengisi kategori null dengan 'unknown'\")\n",
        "        df['product_category_name'] = df['product_category_name'].fillna('unknown')\n",
        "        \n",
        "        # FIX TAMBAHAN: Pastikan kolom angka benar-benar angka (handle error string kosong)\n",
        "        num_cols = ['product_name_lenght', 'product_description_lenght', 'product_photos_qty', \n",
        "                    'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']\n",
        "        for col in num_cols:\n",
        "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "\n",
        "    # 3. STANDARISASI UMUM (Semua File)\n",
        "    # Ubah ke DateTime\n",
        "    date_cols = [col for col in df.columns if 'date' in col or 'timestamp' in col]\n",
        "    for col in date_cols:\n",
        "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
        "        \n",
        "    # 4. SIMPAN KE PROCESSED (REVISI PENTING DI SINI!)\n",
        "    save_file = os.path.join(processed_path, filename)\n",
        "    \n",
        "    # PERUBAHAN: quoting=csv.QUOTE_MINIMAL (0)\n",
        "    # Ini akan membuat nilai Null menjadi kosong (,,) bukan (\"\")\n",
        "    # Sehingga PostgreSQL bisa membacanya sebagai NULL.\n",
        "    df.to_csv(save_file, index=False, quoting=csv.QUOTE_MINIMAL, quotechar='\"') \n",
        "    \n",
        "    print(f\"   Tersimpan di: {save_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MEMULAI PROSES CLEANING & STANDARISASI...\n",
            "\n",
            "\n",
            "--- Memproses: olist_customers_dataset.csv ---\n",
            "   Tersimpan di: ../data/processed/olist_customers_dataset.csv\n",
            "\n",
            "--- Memproses: olist_geolocation_dataset.csv ---\n",
            "   Optimization: Menghapus 261,831 baris duplikat.\n",
            "   Tersimpan di: ../data/processed/olist_geolocation_dataset.csv\n",
            "\n",
            "--- Memproses: olist_order_items_dataset.csv ---\n",
            "   Tersimpan di: ../data/processed/olist_order_items_dataset.csv\n",
            "\n",
            "--- Memproses: olist_order_payments_dataset.csv ---\n",
            "   Tersimpan di: ../data/processed/olist_order_payments_dataset.csv\n",
            "\n",
            "--- Memproses: olist_order_reviews_dataset.csv ---\n",
            "   Fixing: Menghapus karakter newline di komentar...\n",
            "   Tersimpan di: ../data/processed/olist_order_reviews_dataset.csv\n",
            "\n",
            "--- Memproses: olist_orders_dataset.csv ---\n",
            "   Tersimpan di: ../data/processed/olist_orders_dataset.csv\n",
            "\n",
            "--- Memproses: olist_products_dataset.csv ---\n",
            "   Fixing: Mengisi kategori null dengan 'unknown'\n",
            "   Tersimpan di: ../data/processed/olist_products_dataset.csv\n",
            "\n",
            "--- Memproses: olist_sellers_dataset.csv ---\n",
            "   Tersimpan di: ../data/processed/olist_sellers_dataset.csv\n",
            "\n",
            "--- Memproses: product_category_name_translation.csv ---\n",
            "   Tersimpan di: ../data/processed/product_category_name_translation.csv\n",
            "\n",
            "SEMUA FILE SELESAI DIPROSES! Folder 'data/processed' siap di-import.\n"
          ]
        }
      ],
      "source": [
        "# List file yang akan diproses\n",
        "files_to_clean = [\n",
        "    'olist_customers_dataset.csv',\n",
        "    'olist_geolocation_dataset.csv',\n",
        "    'olist_order_items_dataset.csv',\n",
        "    'olist_order_payments_dataset.csv',\n",
        "    'olist_order_reviews_dataset.csv',\n",
        "    'olist_orders_dataset.csv',\n",
        "    'olist_products_dataset.csv',\n",
        "    'olist_sellers_dataset.csv',\n",
        "    'product_category_name_translation.csv'\n",
        "]\n",
        "\n",
        "print(\"MEMULAI PROSES CLEANING & STANDARISASI...\\n\")\n",
        "\n",
        "for f in files_to_clean:\n",
        "    clean_and_save(f)\n",
        "\n",
        "print(\"\\nSEMUA FILE SELESAI DIPROSES! Folder 'data/processed' siap di-import.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyP6AIgoKSjNPZDXHk2hngzo",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
